{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0hgvTmJJTl6"
   },
   "source": [
    "<h1> Install Dependencies </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxUJb0_-JTl9"
   },
   "source": [
    "The libraries needed to run the project is as follows:\n",
    "- torch 1.10.1+cu113\n",
    "- torchvision 0.11.2+cu113\n",
    "- torchaudio 0.10.1+cu113\n",
    "- tqdm\n",
    "- timm 0.4.12\n",
    "- scikit-learn\n",
    "- omegaconf 2.0.6\n",
    "- opencv-python\n",
    "- Pandas\n",
    "- moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6BObvMPZJTl9"
   },
   "outputs": [],
   "source": [
    "#For testing and training of model\n",
    "pip install torch==1.10.1+cu113 torchvision==0.11.2+cu113 torchaudio==0.10.1+cu113 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "pip install tqdm\n",
    "pip install timm==0.4.12 scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQsm3re3JTl_"
   },
   "outputs": [],
   "source": [
    "#For feature extraction\n",
    "pip install omegaconf==2.0.6\n",
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For inference\n",
    "pip install pandas\n",
    "pip install moviepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ponI8gZTIPOw"
   },
   "source": [
    "<h1>Adding New videos/Category to the dataset</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIUT4qUhIatk"
   },
   "source": [
    "To add new videos go to the directory Dataset/Video/  from there drop it in according to the type of actegory its in.\n",
    " \n",
    "To add a new category go to directory Dataset/Video/ from there create a new folder with the new category name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1KqY8SQJTl_"
   },
   "source": [
    "<h1>Feature Extraction</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOW7KcurJTl_"
   },
   "source": [
    "Feature extraction is used to convert the video features numpy format, which can be used to train the model or test the model\n",
    "\n",
    "How to use:\n",
    "1. Run the 1st cell to extract all videos paths and save into a text file\n",
    "3. Run the 2nd cell to commence with feature extraction\n",
    "\n",
    "Check directory \"3104Project/video_features/videoinputs.txt\" for the videos to be extracted\n",
    "\n",
    "Check directory \"3104Project/video_features/output/i3d\" to see the exported numpy file of the extracted videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Run the cell below to extract all videos paths and save into a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def getAllVideoContent():\n",
    "    current_dir = str(os.getcwd())\n",
    "    data_folder = current_dir + \"/Datasets/Video\"\n",
    "    data_folder_content = []\n",
    "\n",
    "    #Loop through to get all the contents inside the data folder\n",
    "    with os.scandir(data_folder) as categories:\n",
    "        for category in categories:\n",
    "            with os.scandir(data_folder + '/' + category.name) as videos:\n",
    "                for video in videos:\n",
    "                    data_folder_content.append(category.name + '/' + video.name)\n",
    "    \n",
    "    return data_folder_content\n",
    "\n",
    "VideosToExtract = getAllVideoContent()\n",
    "\n",
    "f = open(os.getcwd() + \"/video_features/videoinputs.txt\", \"w\")\n",
    "for i in VideosToExtract:\n",
    "  f.write(str(os.getcwd()) + \"/Datasets/Video/\" + str(i) + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to commence with feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_type: i3d\n",
      "stack_size: 16\n",
      "step_size: 16\n",
      "streams: rgb\n",
      "flow_type: raft\n",
      "extraction_fps: null\n",
      "device: cuda:0\n",
      "on_extraction: save_numpy\n",
      "output_path: output\\i3d\n",
      "tmp_path: ./tmp\\i3d\n",
      "keep_tmp_files: false\n",
      "show_pred: false\n",
      "config: null\n",
      "video_paths: null\n",
      "file_with_video_paths: videoinputs.txt\n",
      "\n",
      "Saving features to output\\i3d\n",
      "Device: cuda:0\n",
      "The number of specified videos: 11\n",
      "Features for C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project/Datasets/Video/LivingRoom_Sitting/P11T06C04.mp4 already exist in C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project\\video_features\\output\\i3d/ - skipping..\n",
      "Features for C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project/Datasets/Video/LivingRoom_Sitting/P02T07C05.mp4 already exist in C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project\\video_features\\output\\i3d/ - skipping..\n",
      "Features for C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project/Datasets/Video/LivingRoom_Sitting/P02T06C05.mp4 already exist in C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project\\video_features\\output\\i3d/ - skipping..\n",
      "Features for C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project/Datasets/Video/LivingRoom_Sitting/P02T05C04.mp4 already exist in C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project\\video_features\\output\\i3d/ - skipping..\n",
      "Features for C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project/Datasets/Video/LivingRoom_Sitting/P15T05C05.mp4 already exist in C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project\\video_features\\output\\i3d/ - skipping..\n",
      "Features for C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project/Datasets/Video/DiningArea_EatingBreakfast/P02T11C01.mp4 already exist in C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project\\video_features\\output\\i3d/ - skipping..\n",
      "Features for C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project/Datasets/Video/DiningArea_EatingBreakfast/P02T02C06.mp4 already exist in C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project\\video_features\\output\\i3d/ - skipping..\n",
      "Features for C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project/Datasets/Video/InTheKitchen_Tea/P02T02C07.mp4 already exist in C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project\\video_features\\output\\i3d/ - skipping..\n",
      "Features for C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project/Datasets/Video/LivingRoom_Sitting/P02T04C04.mp4 already exist in C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project\\video_features\\output\\i3d/ - skipping..\n",
      "Features for C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project/Datasets/Video/DiningArea_EatingBreakfast/P02T11C02.mp4 already exist in C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project\\video_features\\output\\i3d/ - skipping..\n",
      "Features for C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project/Datasets/Video/InTheKitchen_Tea/P02T02C03.mp4 already exist in C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project\\video_features\\output\\i3d/ - skipping..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]\n",
      " 45%|####5     | 5/11 [00:00<00:00, 43.29it/s]\n",
      " 91%|######### | 10/11 [00:00<00:00, 45.69it/s]\n",
      "100%|##########| 11/11 [00:00<00:00, 45.32it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(os.getcwd() + '/video_features')\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "!python main.py feature_type=\"i3d\" device=\"cuda:0\" file_with_video_paths=\"videoinputs.txt\" output_path=output on_extraction=save_numpy streams=\"rgb\" stack_size=16 step_size=16\n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Inference </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The team has added the function to do video inference, where users will select the video, then the annotations of the video will be checked against the video, then the annontations will be inserted into the video.\n",
    "\n",
    "How to use:\n",
    "1. Run the 1st cell then select the video category of the video\n",
    "2. Run the 2nd cell then Select the video from the video category **(Rerun this cell if the video category is changed)**\n",
    "3. Run the last cell to commence with the inference of the video\n",
    "\n",
    "Check directory \"3104Project/Annontation/\" for the annontations of all the videos\n",
    "\n",
    "Check directory \"3104Project/Datasets/Video_With_Captions\" for the exported video with the captions generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below and use the dropdown to select the category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf45df89ed449e49222e6cece5bef55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Videos Category:', options=('DiningArea_EatingBreakfast', 'InTheKitchen_Tea', 'LivingRoo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import Video\n",
    "\n",
    "#To get the current directory and set the path of the folder to the data folder\n",
    "def getDatasetFolderVideoContent():\n",
    "    current_dir = str(os.getcwd())\n",
    "    data_folder = current_dir + \"/Datasets/Video\"\n",
    "    data_folder_content = []\n",
    "\n",
    "    #Loop through to get all the contents inside the data folder\n",
    "    with os.scandir(data_folder) as entries:\n",
    "        for entry in entries:\n",
    "            data_folder_content.append(entry.name)\n",
    "    \n",
    "    return data_folder_content\n",
    "\n",
    "#Dropdown to display all videos in data folder\n",
    "infer_video_category_dropdown = widgets.Dropdown(\n",
    "    options = getDatasetFolderVideoContent(),\n",
    "    description = 'Videos Category:',\n",
    "    disabled = False,\n",
    "    style= {'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "display(infer_video_category_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> ***Rerun this cell if the type of video categories is reselected*** </h2>\n",
    "\n",
    "Run the cell below and use the dropdown to select the video you add caption to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9bbdde2e514205af5f0e63b6c2a5bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Videos to Infer:', options=('P02T02C06.mp4', 'P02T11C01.mp4', 'P02T11C02.mp4'), style=De…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#To get the current directory and set the path of the folder to the data folder\n",
    "def getVideoContent():\n",
    "    current_dir = str(os.getcwd())\n",
    "    video_folder = current_dir + \"/Datasets/Video/\" + infer_video_category_dropdown.value\n",
    "    video_folder_content = []\n",
    "\n",
    "    #Loop through to get all the contents inside the data folder\n",
    "    with os.scandir(video_folder) as entries:\n",
    "        for entry in entries:\n",
    "            video_folder_content.append(entry.name)\n",
    "    \n",
    "    return video_folder_content\n",
    "\n",
    "#Dropdown to display all videos in data folder\n",
    "infer_video_dropdown = widgets.Dropdown(\n",
    "    options = getVideoContent(),\n",
    "    description = 'Videos to Infer:',\n",
    "    disabled = False,\n",
    "    style= {'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "display(infer_video_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to commence with the inference of the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video P02T02C06_withCaption.mp4.\n",
      "Moviepy - Writing video P02T02C06_withCaption.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready P02T02C06_withCaption.mp4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\thezh\\\\OneDrive\\\\Desktop\\\\Nvidia Project Local\\\\3104Project/Datasets/Video_With_Captions\\\\P02T02C06_withCaption.mp4'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from moviepy.editor import VideoFileClip\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "#opens up the csv file and save the captions into a pandas data format\n",
    "def parseCaptions(captionFile):\n",
    "    df = pd.read_csv(captionFile)\n",
    "    captionsByFrame = {'captions': []}\n",
    "    captions = \"\"\n",
    "    totalFrames = len(df.index)\n",
    "    initialStartFrame = 0\n",
    "\n",
    "    for index in range(totalFrames):\n",
    "        newStartFrame = int(df['start_frame'][index]) - initialStartFrame\n",
    "        for i in range(newStartFrame):\n",
    "            captionsByFrame['captions'].append(captions)\n",
    "        captions = str(df['event'][index])\n",
    "        initialStartFrame += newStartFrame\n",
    "        if index == totalFrames-1:\n",
    "            newStartFrame = int(df['end_frame'][index]) - initialStartFrame\n",
    "            for j in range(newStartFrame):\n",
    "                captionsByFrame['captions'].append(captions)\n",
    "\n",
    "    return pd.DataFrame(captionsByFrame).iterrows()\n",
    "\n",
    "#Set the captions into the video\n",
    "def captionPlacement(frame):\n",
    "    try:\n",
    "        cv2.putText(frame, str(next(df)[1].captions), (50,50),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 0), 2, cv2.LINE_AA)\n",
    "    except StopIteration:\n",
    "        pass\n",
    "\n",
    "    return frame\n",
    "\n",
    "def inference(inputVideo, captionFile, outputFileName):\n",
    "    global df\n",
    "\n",
    "    df = parseCaptions(captionFile)\n",
    "\n",
    "    # Opens the input video and put the captions in frame by frame and store into a file\n",
    "    inputVideo = VideoFileClip(inputVideo)\n",
    "    videoWithCaptions = inputVideo.fl_image(captionPlacement)\n",
    "    videoWithCaptions.write_videofile(outputFileName, audio=True)\n",
    "    videoWithCaptions.close()\n",
    "\n",
    "videoSelected = os.getcwd() + \"/Datasets/Video/\" + infer_video_category_dropdown.value + '/' + infer_video_dropdown.value\n",
    "annotationDirectory = infer_video_dropdown.value[:3]\n",
    "filename = infer_video_dropdown.value[:len(infer_video_dropdown.value)-4] + \".csv\"\n",
    "annotationCSV = os.getcwd() + \"/Annotation/\" + annotationDirectory + \"/\" + filename\n",
    "outputFilename = infer_video_dropdown.value[:len(infer_video_dropdown.value)-4] + \"_withCaption.mp4\"\n",
    "\n",
    "inference(videoSelected, annotationCSV, outputFilename)\n",
    "\n",
    "sourceFile = os.getcwd() + \"/Datasets/Video_With_Captions/\" + outputFilename\n",
    "\n",
    "if(os.path.isfile(sourceFile)):\n",
    "    os.remove(sourceFile)\n",
    "\n",
    "shutil.move(outputFilename, os.getcwd() + \"/Datasets/Video_With_Captions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sj-_dG37zJmL"
   },
   "source": [
    "<h1> View the video playback of the selected video inside the Datasets Folder. </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYBeKS2_JTmD"
   },
   "source": [
    "In order for users to view the content of the video in the dataset folder, a function to playback all the videos inside the folder is created.\n",
    "\n",
    "Where to add the videos into the video:\n",
    "- \"/Nvidia Project/3104Project/Datasets/Video\"\n",
    "- Add them to their respective categories\n",
    "- Create a new folder if you need a new category\n",
    "\n",
    "How to use:\n",
    "1. Run the 1st cell and use the dropdown to select the category\n",
    "3. Run the 2nd cell and use the dropdown to select the video you wish to view the playback\n",
    "(***Rerun this cell if the category selected is changed, to show the correct content in the category***)\n",
    "5. Run the 3rd cell to view the selected video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below and use the dropdown to select the category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "20d9005fb64547a99357a1e539ac06a0"
     ]
    },
    "id": "l0NCFnEaJTmE",
    "outputId": "81112f03-cb1f-48c7-93b5-f25fac9d318a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a35111b8976f46eeb5f6626f7ae4da13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Videos Category:', options=('DiningArea_EatingBreakfast', 'InTheKitchen_Tea', 'LivingRoo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import Video\n",
    "\n",
    "#To get the current directory and set the path of the folder to the data folder\n",
    "def getDatasetFolderVideoContent():\n",
    "    current_dir = str(os.getcwd())\n",
    "    data_folder = current_dir + \"/Datasets/Video\"\n",
    "    data_folder_content = []\n",
    "\n",
    "    #Loop through to get all the contents inside the data folder\n",
    "    with os.scandir(data_folder) as entries:\n",
    "        for entry in entries:\n",
    "            data_folder_content.append(entry.name)\n",
    "    \n",
    "    return data_folder_content\n",
    "\n",
    "#Dropdown to display all videos in data folder\n",
    "vidCat_dropdown = widgets.Dropdown(\n",
    "    options = getDatasetFolderVideoContent(),\n",
    "    description = 'Videos Category:',\n",
    "    disabled = False,\n",
    "    style= {'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "display(vidCat_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "raKze0GJJTmE"
   },
   "source": [
    "<h2> ***Rerun this cell if the type of video categories is reselected*** </h2>\n",
    "\n",
    "Run the cell below and use the dropdown to select the video you wish to view the playback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "f7e3b3dc34a64f43ba4463e39d641828"
     ]
    },
    "id": "yV99kB8zJTmE",
    "outputId": "995f54be-d943-4126-e87a-e9bf3fb0d325"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85b993326af7477b8e68999307ed1e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Videos to Test:', options=('P02T02C06.mp4', 'P02T11C01.mp4', 'P02T11C02.mp4'), style=Des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#To get the current directory and set the path of the folder to the data folder\n",
    "def getVideoContent():\n",
    "    current_dir = str(os.getcwd())\n",
    "    video_folder = current_dir + \"/Datasets/Video/\" + vidCat_dropdown.value\n",
    "    video_folder_content = []\n",
    "\n",
    "    #Loop through to get all the contents inside the data folder\n",
    "    with os.scandir(video_folder) as entries:\n",
    "        for entry in entries:\n",
    "            video_folder_content.append(entry.name)\n",
    "    \n",
    "    return video_folder_content\n",
    "\n",
    "#Dropdown to display all videos in data folder\n",
    "video_dropdown = widgets.Dropdown(\n",
    "    options = getVideoContent(),\n",
    "    description = 'Videos to Test:',\n",
    "    disabled = False,\n",
    "    style= {'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "display(video_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to view the selected video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qpDxJEN8JTmF"
   },
   "outputs": [],
   "source": [
    "#Set the selected video to the iPyWidget video function and display the video playback\n",
    "video_dir = str(os.getcwd()) + '/Datasets/Video/'\n",
    "selected_video = Video.from_file(video_dir + vidCat_dropdown.value + '/'+ video_dropdown.value)\n",
    "selected_video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y9w1Dv6szY_u"
   },
   "source": [
    "<h1>Model Training Sequence</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHc1A6sYJTmF"
   },
   "source": [
    "The team has created a feature to allow the users to train their pretrained model using TSU.\n",
    "\n",
    "Users are allowed to edit these parameters (To check with PO for parameters):\n",
    "- Epoch Size\n",
    "- Batch Size\n",
    "- Pretrained Model\n",
    "- Type of Data\n",
    "\n",
    "Where to add your model:\n",
    "- \"/Nvidia Project/3104Project/Datasets/PreTrainModel\"\n",
    "\n",
    "How to use:\n",
    "1. Run 1st cell to create the dropdown\n",
    "2. Run 2nd cell to generate the dropdown\n",
    "3. Click on Add to update customisable variables for the training sequence\n",
    "4. Run 3rd cell to commence with training of the Model\n",
    "\n",
    "Where is the model saved:\n",
    "- \"/Nvidia Project/3104Project/Datasets/TrainedModel\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to create the dropdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "IJkNtT0HgHcq"
   },
   "outputs": [],
   "source": [
    "from ipywidgets import Layout, interact, interact_manual, fixed\n",
    "import IPython.display as display\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    batch_size_value = batch_size.value\n",
    "    epoch_value = epoch.value\n",
    "    dataSet_value = dataSet.value\n",
    "    if (dataSet_value.find('CS', 0, len(dataSet_value))):\n",
    "      argv_dict[\"dataSet\"] = \"CS\"\n",
    "    elif (dataSet_value.find('CV', 0, len(dataSet_value))):\n",
    "      argv_dict[\"dataSet\"] = \"CV\"\n",
    "\n",
    "    argv_dict[\"batch_size\"] = batch_size_value\n",
    "    argv_dict[\"epoch\"] = epoch_value\n",
    "    print(\"Values Set: \")\n",
    "    print(\"Batch Size: \", batch_size_value)\n",
    "    print(\"Epoch: \", epoch_value)\n",
    "    print(\"Pre Train Model Selected: \", pretrainedModel.value)\n",
    "    print(\"Data Selected: \", dataSet.value)\n",
    "\n",
    "def on_clear_clicked(b):\n",
    "    clear_output(wait=False)\n",
    "\n",
    "def sidebyside(list1):\n",
    "  side2side = widgets.HBox(list1)\n",
    "  display.display(side2side)\n",
    "  return list1\n",
    "\n",
    "def batchButtonClick(side2side):\n",
    "  button.on_click(on_button_clicked)\n",
    "  clear.on_click(on_clear_clicked)\n",
    "\n",
    "def getDatasetFolderPreTrainModel():\n",
    "    current_dir = str(os.getcwd())\n",
    "    data_folder = current_dir + \"/Datasets/PreTrainModel\"\n",
    "    data_folder_content = []\n",
    "\n",
    "    #Loop through to get all the contents inside the data folder\n",
    "    with os.scandir(data_folder) as entries:\n",
    "        for entry in entries:\n",
    "            data_folder_content.append(entry.name)\n",
    "    \n",
    "    return data_folder_content\n",
    "\n",
    "def getDataFolder():\n",
    "    current_dir = str(os.getcwd())\n",
    "    data_folder = current_dir + \"/data\"\n",
    "    data_folder_content = []\n",
    "\n",
    "    #Loop through to get all the contents inside the data folder\n",
    "    with os.scandir(data_folder) as entries:\n",
    "        for entry in entries:\n",
    "            data_folder_content.append(entry.name)\n",
    "    \n",
    "    return data_folder_content\n",
    "\n",
    "argv_dict = {}\n",
    "flag = False\n",
    "\n",
    "epoch = widgets.IntSlider(\n",
    "    value=2,\n",
    "    min=2,\n",
    "    max=190,\n",
    "    step=2,\n",
    "    description='Epoch:',\n",
    "    disabled=False,\n",
    "    continuous_update=True,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "batch_size = widgets.Dropdown(\n",
    "    value = '1',\n",
    "    placeholder='Choose Batch Size',\n",
    "    options=['1','2', '4', '8', '16', '32', '64'],\n",
    "    description='Batch Size:',\n",
    "    ensure_option=True,\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "pretrainedModel = widgets.Dropdown(\n",
    "    options = getDatasetFolderPreTrainModel(),\n",
    "    description = 'Pretrain Models:',\n",
    "    disabled = False,\n",
    ")\n",
    "\n",
    "dataSet = widgets.Dropdown(\n",
    "    options = getDataFolder(),\n",
    "    description = 'Data:',\n",
    "    disabled = False,\n",
    ")\n",
    "\n",
    "\n",
    "button = widgets.Button(description=\"Add\",icon='check', command=on_button_clicked)\n",
    "clear = widgets.Button(description=\"Clear\",icon='check', command=on_clear_clicked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to generate the dropdown\n",
    "\n",
    "Click on Add to update customisable variables for the training sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223,
     "referenced_widgets": [
      "1a21d06fd50a427281e974526059adf3",
      "2ca2a864de1645f29c57d980cd033da8",
      "c2f314ef2d2041bf95367b904dd7eac2",
      "1cd5d015de454b909ba2f5cd33e6294c",
      "4d9e554ff49549cd87f551df25000601",
      "abaf1854de82499585610d83b4d15fcc",
      "0152c79d28494d0a97c8bbf75b1ddaa4",
      "4cf0da92bc334d5b8613d463922e0bbc",
      "2d25422d40a048058177c4b9e25f51da",
      "91c8988cbcc14bd08192f952b2a35e2d",
      "826d45875a0342a9a4699408cc3c871d",
      "7a306fa8f6d6474898754f5ea217831b",
      "2787953476634e2a9a0b79fcf1ff81b3",
      "bd2cfc3055734bc1b78d780f63350a57",
      "41b7d8e942f3441ca42b9e9639d75ce2",
      "f7198ea373944e6492143832e3c34cef",
      "24023bc1cb9e48029857c7af3190ef7f",
      "8d02f73b32f04506a3dc24ddc802bbf8",
      "a32db8cf334e4f88b6ae0eca5340264e",
      "59f55e3d4fcb42a99eb6f02a712e256b",
      "eee74a9e8f6746a2b25d4ad185f0dc33",
      "09bd98bc7a464ced884f2c2bef67ccb5"
     ]
    },
    "id": "GdsOQtwHEQ85",
    "outputId": "ade9f3b8-36f2-48a0-cf33-bb042380ceb1",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0e0b22f742b4ed3b0490a64442a35a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Batch Size:', options=('1', '2', '4', '8', '16', '32', '64'), value='1'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5df518ccfaf84fcfa1ca9e8d9c846ef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Pretrain Models:', options=('PDAN_TSU_RGB',), value='PDAN_TSU_RGB'), Butt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values Set: \n",
      "Batch Size:  1\n",
      "Epoch:  2\n",
      "Pre Train Model Selected:  PDAN_TSU_RGB\n",
      "Data Selected:  .ipynb_checkpoints\n"
     ]
    }
   ],
   "source": [
    "batchButtonClick(sidebyside([batch_size, epoch, dataSet]))\n",
    "batchButtonClick(sidebyside([pretrainedModel, button, clear]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to commence with training of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3naqbUBSuYCu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random_SEED!!!: 0\n",
      "PDAN\n",
      "batch_size: 1\n",
      "cuda_avail True\n",
      "RGB mode TSU_RGB_i3d_feat/RGB_i3d_16frames_64000_SSD\n",
      "Random_SEED!!!: 0\n",
      "Random_SEED!!!: 0\n",
      "Random_SEED!!!: 0\n",
      "Random_SEED!!!: 0\n",
      "Random_SEED!!!: 0\n",
      "Random_SEED!!!: 0\n",
      "Random_SEED!!!: 0\n",
      "Random_SEED!!!: 0\n",
      "Random_SEED!!!: 0\n",
      "Random_SEED!!!: 0\n",
      "Random_SEED!!!: 0\n",
      "Random_SEED!!!: 0\n",
      "Random_SEED!!!: 0\n",
      "Random_SEED!!!: 0\n",
      "Random_SEED!!!: 0\n",
      "Random_SEED!!!: 0\n",
      "Random_SEED!!!: 0\n",
      "Random_SEED!!!: 0\n",
      "Random_SEED!!!: 0\n",
      "Random_SEED!!!: 0\n",
      "you are processing PDAN\n",
      "loaded ./Datasets/PreTrainModel/PDAN_TSU_RGB\n",
      "pytorch_total_params 5804083\n",
      "num_channel: 512 input_channnel: 1024 num_classes: 51\n",
      "0.0002\n",
      "Epoch 0/1\n",
      "----------\n",
      "train-map: tensor(44.9140)\n",
      "val-map: tensor(32.0678)\n",
      "tensor([42.2309, 48.4907, 41.5985, 42.6820, 40.2896, 43.4211, 39.2577, 28.7293,\n",
      "        41.4218, 19.2233, 17.7037,  5.9982,  0.6269, 35.8853, 36.9116,  2.9232,\n",
      "        22.9525, 52.2472,  2.6292, 70.8249, 27.4463, 45.5043, 52.7016,  2.8799,\n",
      "         1.5855, 61.9453, 33.6975, 54.7716, 58.7572, 14.8907,  5.5335,  1.3326,\n",
      "        39.2023,  2.3516, 42.5855, 86.1209, 39.7135, 15.0244, 24.2986,  9.2497,\n",
      "        66.9380, 27.0583, 16.6874, 68.4038,  2.2502, 79.2251, 66.6669, 29.7100,\n",
      "        20.6144,  1.9365,  0.3265])\n",
      "save here: /Datasets/TrainedModel/PDAN/weight_epoch_0.0002_0\n",
      "Epoch 1/1\n",
      "----------\n",
      "train-map: tensor(46.2325)\n",
      "val-map: tensor(28.6550)\n",
      "tensor([42.1041, 47.8651, 35.8850, 39.1012, 38.4812, 44.4584, 22.4913, 31.6052,\n",
      "        39.9069, 19.8493, 17.2738,  4.6973,  1.0079, 38.2139, 34.5105,  1.6827,\n",
      "        18.4398, 46.5315,  2.2527, 72.6167, 28.0384, 44.8003, 38.2824,  2.6611,\n",
      "         0.8987, 59.9275, 31.4433, 44.4539, 59.9166, 13.8900,  6.2787,  0.9117,\n",
      "        37.3522,  2.8504, 36.6000, 73.7836, 15.8532,  5.6363, 22.4705,  3.9596,\n",
      "        61.4219, 25.0733,  8.8584, 66.0675,  1.8083, 76.4518, 55.5357, 28.4189,\n",
      "         5.9029,  2.6274,  0.2574])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/536 [00:00<?, ?it/s]\n",
      "  1%|          | 4/536 [00:00<00:24, 21.70it/s]\n",
      "  1%|1         | 7/536 [00:00<00:28, 18.60it/s]\n",
      "  2%|1         | 10/536 [00:00<00:25, 20.65it/s]\n",
      "  2%|2         | 13/536 [00:00<00:30, 17.05it/s]\n",
      "  4%|4         | 22/536 [00:00<00:17, 28.93it/s]\n",
      "  5%|4         | 25/536 [00:01<00:18, 27.76it/s]\n",
      "  5%|5         | 29/536 [00:01<00:18, 26.86it/s]\n",
      "  6%|5         | 32/536 [00:01<00:20, 24.06it/s]\n",
      "  7%|7         | 38/536 [00:01<00:16, 30.68it/s]\n",
      "  8%|7         | 42/536 [00:01<00:16, 30.11it/s]\n",
      "  9%|8         | 46/536 [00:01<00:17, 27.93it/s]\n",
      "  9%|9         | 50/536 [00:01<00:16, 29.88it/s]\n",
      " 10%|#         | 54/536 [00:02<00:19, 24.95it/s]\n",
      " 11%|#         | 58/536 [00:02<00:17, 27.32it/s]\n",
      " 12%|#1        | 62/536 [00:02<00:18, 26.09it/s]\n",
      " 12%|#2        | 65/536 [00:02<00:20, 23.36it/s]\n",
      " 13%|#2        | 68/536 [00:02<00:21, 21.94it/s]\n",
      " 13%|#3        | 71/536 [00:02<00:21, 21.50it/s]\n",
      " 14%|#4        | 77/536 [00:03<00:16, 27.55it/s]\n",
      " 15%|#5        | 81/536 [00:03<00:15, 29.08it/s]\n",
      " 16%|#5        | 85/536 [00:03<00:14, 31.44it/s]\n",
      " 17%|#6        | 89/536 [00:03<00:15, 29.07it/s]\n",
      " 17%|#7        | 93/536 [00:03<00:14, 30.94it/s]\n",
      " 18%|#8        | 98/536 [00:03<00:12, 33.72it/s]\n",
      " 19%|#9        | 102/536 [00:03<00:16, 26.72it/s]\n",
      " 20%|##        | 109/536 [00:03<00:12, 34.28it/s]\n",
      " 21%|##1       | 113/536 [00:04<00:13, 31.03it/s]\n",
      " 22%|##2       | 118/536 [00:04<00:12, 33.71it/s]\n",
      " 23%|##2       | 122/536 [00:04<00:13, 30.08it/s]\n",
      " 24%|##3       | 126/536 [00:04<00:14, 27.34it/s]\n",
      " 24%|##4       | 129/536 [00:04<00:19, 20.35it/s]\n",
      " 25%|##4       | 132/536 [00:05<00:20, 19.37it/s]\n",
      " 26%|##5       | 139/536 [00:05<00:14, 26.57it/s]\n",
      " 27%|##6       | 144/536 [00:05<00:13, 29.12it/s]\n",
      " 28%|##7       | 148/536 [00:05<00:14, 25.97it/s]\n",
      " 29%|##8       | 153/536 [00:05<00:12, 30.28it/s]\n",
      " 29%|##9       | 157/536 [00:05<00:13, 27.17it/s]\n",
      " 30%|###       | 161/536 [00:06<00:19, 19.69it/s]\n",
      " 31%|###       | 164/536 [00:06<00:18, 20.26it/s]\n",
      " 31%|###1      | 168/536 [00:06<00:15, 23.69it/s]\n",
      " 32%|###2      | 173/536 [00:06<00:13, 26.22it/s]\n",
      " 34%|###3      | 181/536 [00:06<00:10, 34.93it/s]\n",
      " 35%|###4      | 185/536 [00:06<00:12, 28.90it/s]\n",
      " 35%|###5      | 189/536 [00:07<00:16, 21.35it/s]\n",
      " 36%|###5      | 192/536 [00:07<00:15, 22.25it/s]\n",
      " 36%|###6      | 195/536 [00:07<00:16, 20.38it/s]\n",
      " 37%|###6      | 198/536 [00:07<00:19, 17.64it/s]\n",
      " 38%|###8      | 206/536 [00:07<00:11, 28.07it/s]\n",
      " 39%|###9      | 210/536 [00:08<00:13, 24.61it/s]\n",
      " 40%|###9      | 214/536 [00:08<00:15, 21.27it/s]\n",
      " 41%|####1     | 222/536 [00:08<00:11, 28.31it/s]\n",
      " 42%|####2     | 226/536 [00:08<00:12, 24.46it/s]\n",
      " 43%|####2     | 229/536 [00:08<00:13, 22.09it/s]\n",
      " 44%|####3     | 234/536 [00:09<00:12, 24.49it/s]\n",
      " 44%|####4     | 237/536 [00:09<00:12, 23.06it/s]\n",
      " 45%|####4     | 240/536 [00:09<00:14, 20.17it/s]\n",
      " 45%|####5     | 243/536 [00:09<00:14, 20.65it/s]\n",
      " 46%|####5     | 246/536 [00:09<00:14, 20.67it/s]\n",
      " 47%|####7     | 253/536 [00:09<00:09, 28.32it/s]\n",
      " 48%|####7     | 256/536 [00:10<00:10, 27.47it/s]\n",
      " 48%|####8     | 259/536 [00:10<00:11, 23.62it/s]\n",
      " 49%|####8     | 262/536 [00:10<00:13, 20.79it/s]\n",
      " 49%|####9     | 265/536 [00:10<00:14, 19.35it/s]\n",
      " 50%|#####     | 268/536 [00:10<00:14, 18.39it/s]\n",
      " 50%|#####     | 270/536 [00:10<00:14, 18.56it/s]\n",
      " 51%|#####1    | 275/536 [00:11<00:12, 21.43it/s]\n",
      " 52%|#####1    | 278/536 [00:11<00:11, 22.61it/s]\n",
      " 53%|#####2    | 282/536 [00:11<00:09, 25.75it/s]\n",
      " 53%|#####3    | 286/536 [00:11<00:09, 27.42it/s]\n",
      " 54%|#####4    | 290/536 [00:11<00:09, 25.66it/s]\n",
      " 55%|#####4    | 293/536 [00:11<00:11, 20.77it/s]\n",
      " 56%|#####5    | 299/536 [00:12<00:09, 24.69it/s]\n",
      " 56%|#####6    | 302/536 [00:12<00:11, 21.06it/s]\n",
      " 57%|#####7    | 306/536 [00:12<00:10, 22.40it/s]\n",
      " 58%|#####8    | 312/536 [00:12<00:07, 29.16it/s]\n",
      " 60%|#####9    | 319/536 [00:12<00:05, 37.95it/s]\n",
      " 60%|######    | 324/536 [00:12<00:07, 28.10it/s]\n",
      " 61%|######1   | 329/536 [00:12<00:06, 31.20it/s]\n",
      " 62%|######2   | 333/536 [00:13<00:07, 26.95it/s]\n",
      " 63%|######3   | 338/536 [00:13<00:06, 29.01it/s]\n",
      " 64%|######3   | 342/536 [00:13<00:07, 24.76it/s]\n",
      " 64%|######4   | 345/536 [00:13<00:08, 21.76it/s]\n",
      " 66%|######5   | 352/536 [00:13<00:06, 29.62it/s]\n",
      " 66%|######6   | 356/536 [00:14<00:06, 27.44it/s]\n",
      " 67%|######7   | 360/536 [00:14<00:05, 29.65it/s]\n",
      " 68%|######8   | 365/536 [00:14<00:05, 31.45it/s]\n",
      " 69%|######8   | 369/536 [00:14<00:05, 29.57it/s]\n",
      " 70%|######9   | 373/536 [00:14<00:05, 28.31it/s]\n",
      " 70%|#######   | 377/536 [00:14<00:05, 26.78it/s]\n",
      " 71%|#######   | 380/536 [00:14<00:06, 23.49it/s]\n",
      " 72%|#######2  | 386/536 [00:15<00:05, 28.65it/s]\n",
      " 73%|#######2  | 390/536 [00:15<00:04, 29.85it/s]\n",
      " 74%|#######3  | 394/536 [00:15<00:05, 25.42it/s]\n",
      " 74%|#######4  | 397/536 [00:15<00:06, 20.91it/s]\n",
      " 75%|#######4  | 400/536 [00:15<00:06, 20.21it/s]\n",
      " 75%|#######5  | 403/536 [00:15<00:06, 20.61it/s]\n",
      " 76%|#######5  | 406/536 [00:16<00:06, 21.55it/s]\n",
      " 76%|#######6  | 409/536 [00:16<00:06, 19.31it/s]\n",
      " 77%|#######6  | 412/536 [00:16<00:06, 19.36it/s]\n",
      " 77%|#######7  | 415/536 [00:16<00:06, 19.39it/s]\n",
      " 78%|#######7  | 417/536 [00:16<00:06, 18.32it/s]\n",
      " 78%|#######8  | 419/536 [00:16<00:06, 18.59it/s]\n",
      " 79%|#######8  | 422/536 [00:16<00:05, 20.57it/s]\n",
      " 79%|#######9  | 425/536 [00:17<00:05, 19.80it/s]\n",
      " 80%|########  | 429/536 [00:17<00:04, 23.68it/s]\n",
      " 81%|########  | 432/536 [00:17<00:04, 23.35it/s]\n",
      " 81%|########1 | 435/536 [00:17<00:04, 20.85it/s]\n",
      " 82%|########1 | 439/536 [00:17<00:04, 21.20it/s]\n",
      " 82%|########2 | 442/536 [00:17<00:04, 18.84it/s]\n",
      " 84%|########3 | 449/536 [00:18<00:03, 26.23it/s]\n",
      " 84%|########4 | 452/536 [00:18<00:03, 26.17it/s]\n",
      " 85%|########4 | 455/536 [00:18<00:03, 23.52it/s]\n",
      " 85%|########5 | 458/536 [00:18<00:03, 24.39it/s]\n",
      " 86%|########6 | 463/536 [00:18<00:02, 30.24it/s]\n",
      " 87%|########7 | 468/536 [00:18<00:02, 32.16it/s]\n",
      " 90%|########9 | 480/536 [00:18<00:01, 44.40it/s]\n",
      " 90%|######### | 485/536 [00:19<00:01, 31.83it/s]\n",
      " 91%|#########1| 489/536 [00:19<00:01, 28.27it/s]\n",
      " 92%|#########1| 493/536 [00:19<00:01, 27.05it/s]\n",
      " 93%|#########2| 497/536 [00:19<00:01, 28.98it/s]\n",
      " 93%|#########3| 501/536 [00:19<00:01, 27.32it/s]\n",
      " 95%|#########5| 510/536 [00:20<00:00, 35.81it/s]\n",
      " 96%|#########5| 514/536 [00:20<00:00, 29.22it/s]\n",
      " 97%|#########6| 518/536 [00:20<00:00, 25.05it/s]\n",
      " 98%|#########7| 525/536 [00:20<00:00, 32.10it/s]\n",
      " 99%|#########8| 529/536 [00:20<00:00, 26.09it/s]\n",
      "100%|#########9| 535/536 [00:20<00:00, 29.07it/s]\n",
      "100%|##########| 536/536 [00:21<00:00, 25.41it/s]\n",
      "\n",
      "  0%|          | 0/536 [00:00<?, ?it/s]\n",
      "  1%|          | 3/536 [00:00<00:19, 27.78it/s]\n",
      "  3%|2         | 14/536 [00:00<00:08, 61.86it/s]\n",
      "  4%|3         | 20/536 [00:00<00:16, 32.16it/s]\n",
      "  5%|4         | 25/536 [00:00<00:15, 32.46it/s]\n",
      "  7%|6         | 36/536 [00:00<00:11, 42.76it/s]\n",
      "  8%|7         | 41/536 [00:01<00:11, 41.77it/s]\n",
      "  9%|8         | 46/536 [00:01<00:11, 42.25it/s]\n",
      " 10%|#         | 56/536 [00:01<00:09, 52.35it/s]\n",
      " 12%|#1        | 62/536 [00:01<00:09, 50.58it/s]\n",
      " 13%|#3        | 72/536 [00:01<00:07, 61.36it/s]\n",
      " 15%|#4        | 79/536 [00:01<00:09, 45.83it/s]\n",
      " 16%|#5        | 85/536 [00:02<00:12, 34.93it/s]\n",
      " 18%|#7        | 94/536 [00:02<00:10, 41.69it/s]\n",
      " 18%|#8        | 99/536 [00:02<00:10, 42.21it/s]\n",
      " 20%|#9        | 105/536 [00:02<00:09, 44.37it/s]\n",
      " 22%|##1       | 117/536 [00:02<00:07, 54.64it/s]\n",
      " 23%|##2       | 123/536 [00:02<00:07, 55.57it/s]\n",
      " 25%|##4       | 133/536 [00:02<00:07, 55.88it/s]\n",
      " 26%|##5       | 139/536 [00:03<00:09, 41.60it/s]\n",
      " 27%|##6       | 144/536 [00:03<00:09, 40.36it/s]\n",
      " 28%|##8       | 151/536 [00:03<00:09, 40.39it/s]\n",
      " 29%|##9       | 157/536 [00:03<00:09, 38.40it/s]\n",
      " 31%|###       | 165/536 [00:03<00:08, 43.13it/s]\n",
      " 32%|###1      | 170/536 [00:03<00:10, 35.55it/s]\n",
      " 32%|###2      | 174/536 [00:04<00:11, 31.81it/s]\n",
      " 33%|###3      | 178/536 [00:04<00:14, 25.33it/s]\n",
      " 34%|###3      | 181/536 [00:04<00:14, 24.13it/s]\n",
      " 36%|###6      | 193/536 [00:04<00:08, 39.04it/s]\n",
      " 37%|###7      | 200/536 [00:04<00:07, 43.04it/s]\n",
      " 38%|###8      | 205/536 [00:05<00:10, 31.84it/s]\n",
      " 40%|####      | 216/536 [00:05<00:07, 42.37it/s]\n",
      " 41%|####1     | 221/536 [00:05<00:07, 42.39it/s]\n",
      " 43%|####3     | 233/536 [00:05<00:05, 57.49it/s]\n",
      " 45%|####4     | 240/536 [00:05<00:04, 60.16it/s]\n",
      " 46%|####6     | 248/536 [00:05<00:05, 56.29it/s]\n",
      " 48%|####7     | 255/536 [00:05<00:05, 54.49it/s]\n",
      " 50%|#####     | 270/536 [00:05<00:03, 74.43it/s]\n",
      " 52%|#####2    | 279/536 [00:06<00:03, 64.50it/s]\n",
      " 54%|#####3    | 287/536 [00:06<00:04, 53.56it/s]\n",
      " 55%|#####5    | 296/536 [00:06<00:04, 59.32it/s]\n",
      " 57%|#####7    | 307/536 [00:06<00:03, 59.67it/s]\n",
      " 59%|#####8    | 314/536 [00:07<00:05, 39.63it/s]\n",
      " 60%|#####9    | 320/536 [00:07<00:06, 32.57it/s]\n",
      " 61%|######1   | 327/536 [00:07<00:06, 33.24it/s]\n",
      " 62%|######2   | 335/536 [00:07<00:05, 38.80it/s]\n",
      " 64%|######3   | 341/536 [00:07<00:04, 42.50it/s]\n",
      " 65%|######5   | 349/536 [00:07<00:04, 42.74it/s]\n",
      " 66%|######6   | 354/536 [00:08<00:04, 39.03it/s]\n",
      " 67%|######6   | 359/536 [00:08<00:05, 35.09it/s]\n",
      " 68%|######8   | 366/536 [00:08<00:04, 35.33it/s]\n",
      " 70%|######9   | 373/536 [00:08<00:04, 37.50it/s]\n",
      " 72%|#######1  | 385/536 [00:08<00:03, 44.47it/s]\n",
      " 73%|#######2  | 390/536 [00:08<00:03, 45.14it/s]\n",
      " 75%|#######4  | 401/536 [00:09<00:02, 49.60it/s]\n",
      " 76%|#######6  | 409/536 [00:09<00:02, 47.71it/s]\n",
      " 79%|#######9  | 426/536 [00:09<00:01, 69.03it/s]\n",
      " 81%|########  | 434/536 [00:09<00:01, 64.32it/s]\n",
      " 82%|########2 | 441/536 [00:09<00:01, 63.73it/s]\n",
      " 84%|########3 | 448/536 [00:09<00:01, 54.82it/s]\n",
      " 86%|########5 | 460/536 [00:10<00:01, 65.68it/s]\n",
      " 88%|########7 | 470/536 [00:10<00:01, 62.17it/s]\n",
      " 89%|########8 | 477/536 [00:10<00:01, 48.25it/s]\n",
      " 90%|######### | 483/536 [00:10<00:01, 42.71it/s]\n",
      " 91%|#########1| 488/536 [00:10<00:01, 41.74it/s]\n",
      " 92%|#########1| 493/536 [00:10<00:01, 41.13it/s]\n",
      " 93%|#########2| 498/536 [00:11<00:00, 39.52it/s]\n",
      " 94%|#########3| 503/536 [00:11<00:00, 34.91it/s]\n",
      " 95%|#########4| 507/536 [00:11<00:00, 35.82it/s]\n",
      " 95%|#########5| 511/536 [00:11<00:00, 36.68it/s]\n",
      " 97%|#########6| 519/536 [00:11<00:00, 45.88it/s]\n",
      " 98%|#########7| 524/536 [00:11<00:00, 39.70it/s]\n",
      "100%|##########| 536/536 [00:11<00:00, 45.39it/s]\n",
      "C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project\\models.py:88: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(self.key_conv.weight, mode='fan_out')\n",
      "C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project\\models.py:89: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(self.value_conv.weight, mode='fan_out')\n",
      "C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project\\models.py:90: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(self.query_conv.weight, mode='fan_out')\n",
      "C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project\\models.py:91: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  init.normal(self.rel_t, 0, 1)\n",
      "C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\venv\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\venv\\lib\\site-packages\\torch\\nn\\functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\venv\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project\\apmeter.py:108: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  rg = torch.range(1, self.scores.size(0)).float()\n",
      "C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project\\apmeter.py:137: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen/native/IndexingUtils.h:28.)\n",
      "  ap[k] = precision[truth.byte()].sum() / max(truth.sum(), 1)\n"
     ]
    }
   ],
   "source": [
    "#Change directory to pipline directory to run the training sequence and change back to root directory\n",
    "# os.getcwd()\n",
    "# os.chdir('/content/Toyota_Smarthome/pipline')\n",
    "pretrained_model = \"Datasets/PreTrainModel/\" + pretrainedModel.value\n",
    "user_input_epoch = argv_dict[\"epoch\"]\n",
    "user_input_batch_size = argv_dict[\"batch_size\"]\n",
    "user_input_dataSet = argv_dict[\"dataSet\"]\n",
    "\n",
    "!python train.py \\\n",
    "-dataset TSU \\\n",
    "-mode rgb \\\n",
    "-gpu 1 \\\n",
    "-split_setting $user_input_dataSet \\\n",
    "-model PDAN \\\n",
    "-train True \\\n",
    "-num_channel 512 \\\n",
    "-lr 0.0002 \\\n",
    "-kernelsize 3 \\\n",
    "-APtype map \\\n",
    "-epoch $user_input_epoch \\\n",
    "-batch_size $user_input_batch_size \\\n",
    "-comp_info TSU_CS_RGB_PDAN \\\n",
    "-load_model ./{pretrained_model}\n",
    "# !python train.py -dataset TSU -mode rgb -split_setting $user_input_dataSet -model PDAN -train True -num_channel 512 -lr 0.0002 -kernelsize 3 -APtype map -epoch $user_input_epoch -batch_size $user_input_batch_size -comp_info TSU_CS_RGB_PDAN -load_model ./{pretrained_model} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check if your computer is cuda compatible to run the codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IIjXx-S7JTmG",
    "outputId": "834ebb84-ccfe-4589-ad1f-83c575386cd7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Used to see if your computer have CUDA to run torch\n",
    "import torch\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "torch.cuda.current_device()\n",
    "\n",
    "torch.cuda.device_count()\n",
    "# # setting device on GPU if available, else CPU\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print('Using device:', device)\n",
    "# print()\n",
    "\n",
    "# #Additional Info when using cuda\n",
    "# if device.type == 'cuda':\n",
    "#     print(torch.cuda.get_device_name(0))\n",
    "#     print('Memory Usage:')\n",
    "#     print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "#     print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "    \n",
    "# torch.rand(10, device=device)\n",
    "\n",
    "# torch.cuda.get_device_name(0)\n",
    "# torch.cuda.set_device(0)\n",
    "# torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the graphic card information of your system and check your CUDA version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LeTg3hmaJTmH",
    "outputId": "ddb9b16a-0283-4661-d0ef-c7da48b86df7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Sep 30 17:37:09 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 516.94       Driver Version: 516.94       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   53C    P8     4W /  N/A |    598MiB /  4096MiB |      4%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     14120      C   ...ython\\Python38\\python.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntxIx0PgJTmH"
   },
   "source": [
    "<h1>Extract CS/CV</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9O97o8zJTmH"
   },
   "source": [
    "This feature is used to extract the existing data inside the file \"smarthome_CS_51.json\" or \"smarthome_CV_51.json\". With this feature, user is able to choose which video data they wish to extract from these 2 files using the video as the input and extract them into a new JSON file.\n",
    "\n",
    "How to use:\n",
    "1. Run the 1st cell to generate the dropdown for selection\n",
    "2. Choose the data the user wishes to add to the new json file\n",
    "3. Press the add button to save the list of video data\n",
    "3. (Optional) Press Set Video to view video playback\n",
    "4. (Optional) Run 2nd Cell to view the selected video playback\n",
    "5. Run the 3rd cell to save the file into the new JSON file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to generate the dropdown for selection,\n",
    "choose the data the user wishes to add to the new json file.\n",
    "Press the add button to save the list of video data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "e004577271d44c05ad03c683cf3cf0ee",
      "03e0ed1896794654b307d1fdf7aea476"
     ]
    },
    "id": "k21dY6j4JTmH",
    "outputId": "2afbe38b-48f1-47e0-9b0d-c392ba6d4307"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4098d3d0f2c4524b21eef86e802f00d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Folder', options=('DiningArea_EatingBreakfast', 'InTheKitchen_Tea'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa1514d11ef4e428103e2a37afdab45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(LoadedButton(description='Add', style=ButtonStyle()), LoadedButton(description='Set Video', sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Added:  P02T02C06.mp4\n",
      "Video Added:  P02T11C01.mp4\n",
      "Video Added:  P02T11C02.mp4\n"
     ]
    }
   ],
   "source": [
    "from ipywidgets import interact, Dropdown\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "from traitlets import traitlets\n",
    "from ipywidgets import Video\n",
    "import os\n",
    "import json\n",
    "\n",
    "current_dir = str(os.getcwd())\n",
    "data_dir = current_dir + \"/Datasets/Video\"\n",
    "\n",
    "def getDatasetFolderVideo():\n",
    "    data_folder_dict = {}\n",
    "    data_videos = []\n",
    "    #Loop through to get all the contents inside the data folder\n",
    "    with os.scandir(data_dir) as entries:\n",
    "        for entry in entries:\n",
    "            for content in (os.scandir(data_dir + \"/\" + entry.name)):\n",
    "                data_videos.append(content.name)\n",
    "            data_folder_dict[entry.name] = data_videos\n",
    "            data_videos = []    \n",
    "    return data_folder_dict\n",
    "\n",
    "#-------------------------------------------------------------- \n",
    "vidCat_dropdown = widgets.Dropdown(\n",
    "    options = [\"Training\", \"Testing\"],\n",
    "    description = 'Videos Category:',\n",
    "    disabled = False,\n",
    "    style= {'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "\n",
    "def on_clear_clicked(b):\n",
    "    selected_training_list.clear()\n",
    "\n",
    "def sidebyside(list1):\n",
    "    side2side = widgets.HBox(list1)\n",
    "    display(side2side)\n",
    "    return list1\n",
    "\n",
    "def batchButtonClick1(side2side):\n",
    "    vidJsonBtn.on_click(add_video)\n",
    "    setVideoPlayBtn.on_click(set_video)\n",
    "\n",
    "\n",
    "class LoadedButton(widgets.Button):\n",
    "    \"\"\"A button that can holds a value as a attribute.\"\"\"\n",
    "\n",
    "    def __init__(self, value=None, *args, **kwargs):\n",
    "        super(LoadedButton, self).__init__(*args, **kwargs)\n",
    "        # Create the value attribute.\n",
    "        self.add_traits(value=traitlets.Any(value))\n",
    "\n",
    "def add_video(trg):\n",
    "    try:\n",
    "        vidValue = videoW.value\n",
    "        trg.value = Video.from_file(data_dir + '/'+ folderW.value + '/' + vidValue)\n",
    "        split = videoW.value.split(('.'))\n",
    "        if split[0] in selected_list:\n",
    "            print(\"Video is already in selected list, please select another video!\")\n",
    "        else:\n",
    "            selected_list.append(split[0])\n",
    "            print(\"Video Added: \", videoW.value)\n",
    "    except Exception as e:\n",
    "        print(\"Error: \", e)\n",
    "\n",
    "def set_video(trg):\n",
    "    vidValue = videoW.value\n",
    "    trg.value = Video.from_file(data_dir + '/'+ folderW.value + '/' + vidValue)\n",
    "    print(vidValue + \" selected for playback, please run the next cell\")\n",
    "    \n",
    "\n",
    "vidJsonBtn = LoadedButton(description=\"Add\", value=1)\n",
    "setVideoPlayBtn = LoadedButton(description=\"Set Video\", value=1)\n",
    "\n",
    "\n",
    "video_folder_dict = getDatasetFolderVideo()\n",
    "folderW = Dropdown(options = video_folder_dict.keys())\n",
    "videoW = Dropdown()\n",
    "\n",
    "def update_videoW_options(*args):\n",
    "    videoW.options = video_folder_dict[folderW.value]\n",
    "videoW.observe(update_videoW_options) #update videoW.options based on folderW.value.\n",
    "\n",
    "selected_list = []\n",
    "\n",
    "cv_subset_value = \"\"\n",
    "cs_subset_value = \"\"\n",
    "    \n",
    "@interact(Folder = folderW, Video = videoW)\n",
    "def print_videos(Folder, Video):\n",
    "    global cv_subset_value\n",
    "    global cs_subset_value\n",
    "    cvFile = current_dir + \"/data/smarthome_CV_51.json\"\n",
    "    csFile = current_dir + \"/data/smarthome_CS_51.json\"\n",
    "    fCV = open(cvFile)\n",
    "    fCS = open(csFile)\n",
    "    dataCV = json.load(fCV)\n",
    "    dataCS = json.load(fCS)\n",
    "    split = Video.split(('.'))\n",
    "    cv_subset_value = {'subset': dataCV[split[0]]['subset']}\n",
    "    cs_subset_value = {'subset': dataCS[split[0]]['subset']}\n",
    "    print(Video, \"from\", Folder, \"folder selected\")\n",
    "    print(\"subset of\", cv_subset_value['subset'], \"in cv file and subset of\", cs_subset_value['subset'], \"in cs file\")\n",
    "    print(\"Click on add to add to selected list\")\n",
    "    print(\"selected list:\", selected_list)\n",
    "\n",
    "batchButtonClick1(sidebyside([vidJsonBtn, setVideoPlayBtn]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to delete the JSON from the list, select the video name then click on remove to remove the video from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "DXuRadRNJn0o"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94aae7cea32d4cf5a1655aab10a18cb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='selected_videos', options=('videos',), value='videos'), Dropdown(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33280a5efa50466e8e1c318eae908e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(LoadedButton(description='Remove', style=ButtonStyle()),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def batchButtonClick2(side2side):\n",
    "    remove_selected_vid.on_click(remove_video)\n",
    "    \n",
    "remove_selected_vid = LoadedButton(description=\"Remove\", value=1)\n",
    "\n",
    "def remove_video(trg):\n",
    "    try:\n",
    "        vidValue = videoNameW.value\n",
    "        if vidValue in selected_list:\n",
    "            selected_list.remove(vidValue)\n",
    "            print(vidValue, \"removed from selected list\")\n",
    "        else:\n",
    "            print(\"already removed\")\n",
    "    except Exception as e:\n",
    "        print(\"Error: \", e)\n",
    "\n",
    "def getTrainTestList():\n",
    "    train_test_dict = {}\n",
    "    train_list = []\n",
    "    for train in selected_list:\n",
    "        train_list.append(train)\n",
    "    train_test_dict['videos'] = train_list\n",
    "    return train_test_dict\n",
    "\n",
    "\n",
    "train_test_dict = getTrainTestList()\n",
    "trainortestW = Dropdown(options = train_test_dict.keys())\n",
    "videoNameW = Dropdown()\n",
    "\n",
    "def update_videoNameW_options(*args):\n",
    "    videoNameW.options = train_test_dict[trainortestW.value]\n",
    "videoNameW.observe(update_videoNameW_options) #update videoW.options based on folderW.value.\n",
    "\n",
    "@interact(selected_videos = trainortestW, videoname = videoNameW)\n",
    "def print_videos_removal(selected_videos, videoname):\n",
    "    print(\"selected list:\", selected_list)\n",
    "    \n",
    "batchButtonClick2(sidebyside([remove_selected_vid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5_qdIipTJTmI",
    "outputId": "6b5de9f2-2939-4ed3-c39b-a7b7037ce567"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setVideoPlayBtn.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to save the file into the new JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "KIj5m2gRJTmI",
    "outputId": "cad04d3e-8829-47b8-c643-41cc133b5661"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving completed:  smarthome_CV_51_new.json\n",
      "saving completed:  smarthome_CS_51_new.json\n"
     ]
    }
   ],
   "source": [
    "def convListToStr(selList):\n",
    "    string = \"\"\n",
    "    for i in selList:\n",
    "        string+= \" \" + i\n",
    "    return string[1:]\n",
    "    \n",
    "!python validate_train_test.py \\\n",
    "-selected_videos \"{convListToStr(selected_list)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9VpPL52TDsK"
   },
   "source": [
    "<h1> Select Videos By Percentage </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature is used to extract the existing data inside the file \"smarthome_CS_51.json\" or \"smarthome_CV_51.json\". With this feature, user is able to choose percentage of video data they wish to extract from these 2 files at random using the video as the input and extract them into a new JSON file.\n",
    "\n",
    "How to use:\n",
    "1. Run the 1st cell to display slider\n",
    "2. Choose the percentage of video input the user wishes to add to the new json file by sliding the slider\n",
    "3. Press the generate button to save the file into the new JSON file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to display slider, choose the percentage of video input the user wishes to add to the new json file by sliding the slider, then press the generate button to save the file into the new JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5-X6YI11TLAO"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dfd80a3775845f8b218ba2bdce33ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntSlider(value=80, description='Percentage:', min=1), Button(description='Generate', icon='che…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage: 80\n",
      "Number of videos: 428\n",
      "saving completed:  smarthome_CV_51_new.json\n",
      "saving completed:  smarthome_CS_51_new.json\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "videoPercentage = widgets.IntSlider(\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Percentage:',\n",
    "    disabled=False,\n",
    "    continuous_update=True,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    "    value = 80\n",
    ")\n",
    "\n",
    "def sidebyside(list1):\n",
    "    side2side = widgets.HBox(list1)\n",
    "    display(side2side)\n",
    "    return list1\n",
    "\n",
    "def generate_button_action(b):\n",
    "    percentage = videoPercentage.value\n",
    "    print(\"Percentage:\", percentage)\n",
    "    !python validate_train_test.py -percentage \"{percentage}\"\n",
    "\n",
    "generateButton = widgets.Button(description=\"Generate\",icon='check', command=generate_button_action)\n",
    "\n",
    "def batchButtonClick3(side2side):\n",
    "    generateButton.on_click(generate_button_action)\n",
    "    \n",
    "batchButtonClick3(sidebyside([videoPercentage, generateButton]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6mNPGWCJTmI"
   },
   "source": [
    "<h1> Model Testing Sequence </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beWDxWchJTmI"
   },
   "source": [
    "After training, testing needed to be done to verify that the model is trained properly. The team has created a function to run and save the logits of the model into a PKL file for evaluation.\n",
    "\n",
    "How to use:\n",
    "1. Run the first cell to generate a dropdown to view all the type of trained model category\n",
    "2. Run the second cell to generate a dropdown to view all trained model in the category\n",
    "3. Run the third cell to save the logit of the model into a PKL file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to generate a dropdown for the trained model category. Select the type of model you wish to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "37ce8e18ea5c4f7fba50e13aef597d40"
     ]
    },
    "id": "90ij61wBJTmI",
    "outputId": "17d8c465-5204-4fbf-f265-6807cc9e79ce"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a0436371c04597b5452e848df57001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Type of Trained Model:', options=('PDAN',), style=DescriptionStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import Video\n",
    "\n",
    "#To get the current directory and set the path of the folder to the data folder\n",
    "def getTrainedModelType():\n",
    "    current_dir = str(os.getcwd())\n",
    "    data_folder = current_dir + \"/Datasets/TrainedModel\"\n",
    "    data_folder_content = []\n",
    "\n",
    "    #Loop through to get all the contents inside the data folder\n",
    "    with os.scandir(data_folder) as entries:\n",
    "        for entry in entries:\n",
    "            data_folder_content.append(entry.name)\n",
    "    \n",
    "    return data_folder_content\n",
    "\n",
    "#Dropdown to display all videos in data folder\n",
    "preTrainedModelType_dropdown = widgets.Dropdown(\n",
    "    options = getTrainedModelType(),\n",
    "    description = 'Type of Trained Model:',\n",
    "    disabled = False,\n",
    "    style= {'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "display(preTrainedModelType_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VVUk-ap4JTmJ"
   },
   "source": [
    "<h2> ***Rerun this cell if type of trained model is reselected*** </h2>\n",
    "\n",
    "Run the cell below to generate a dropdown to view all trained model in the category. Select the model you wish to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "52635903203f459692e26a97462e9cbb"
     ]
    },
    "id": "nrsIT7fMJTmJ",
    "outputId": "ac7075b2-02f4-4e76-ee3f-544459d1cc88"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddaccf125df94fcd8b9dcfd12d0a2158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Trained Model:', options=('model_PDAN_TSU', 'weight_epoch_0.0002_0', 'weight_epoch_0.000…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#To get the current directory and set the path of the folder to the data folder\n",
    "def getTrainedModel():\n",
    "    current_dir = str(os.getcwd())\n",
    "    data_folder = current_dir + \"/Datasets/TrainedModel/\" + preTrainedModelType_dropdown.value\n",
    "    data_folder_content = []\n",
    "\n",
    "    #Loop through to get all the contents inside the data folder\n",
    "    with os.scandir(data_folder) as entries:\n",
    "        for entry in entries:\n",
    "            data_folder_content.append(entry.name)\n",
    "    \n",
    "    return data_folder_content\n",
    "\n",
    "#Dropdown to display all videos in data folder\n",
    "preTrainedModel_dropdown = widgets.Dropdown(\n",
    "    options = getTrainedModel(),\n",
    "    description = 'Trained Model:',\n",
    "    disabled = False,\n",
    "    style= {'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "display(preTrainedModel_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to save the logit of the model into a PKL file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "E3pBr8KwJTmJ",
    "outputId": "1db98288-309b-4686-d18f-912bc93bffb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random_SEED!!!: 0\n",
      "PDAN\n",
      "batch_size: 2\n",
      "cuda_avail True\n",
      "RGB mode TSU_RGB_i3d_feat/RGB_i3d_16frames_64000_SSD\n",
      "Random_SEED!!!: 0\n",
      "Random_SEED!!!: 0\n",
      "you are processing PDAN\n",
      "P16T15C03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/536 [00:00<?, ?it/s]\n",
      "  1%|          | 4/536 [00:00<00:20, 25.58it/s]\n",
      "  1%|1         | 7/536 [00:00<00:24, 21.82it/s]\n",
      "  2%|1         | 10/536 [00:00<00:22, 23.46it/s]\n",
      "  2%|2         | 13/536 [00:00<00:26, 19.42it/s]\n",
      "  4%|4         | 22/536 [00:00<00:15, 32.80it/s]\n",
      "  5%|4         | 26/536 [00:00<00:16, 31.54it/s]\n",
      "  6%|5         | 30/536 [00:01<00:18, 27.91it/s]\n",
      "  6%|6         | 33/536 [00:01<00:17, 28.33it/s]\n",
      "  7%|7         | 39/536 [00:01<00:14, 34.12it/s]\n",
      "  8%|8         | 43/536 [00:01<00:16, 29.96it/s]\n",
      "  9%|9         | 49/536 [00:01<00:15, 32.32it/s]\n",
      " 10%|9         | 53/536 [00:01<00:16, 30.08it/s]\n",
      " 11%|#         | 57/536 [00:01<00:15, 31.59it/s]\n",
      " 11%|#1        | 61/536 [00:02<00:16, 29.60it/s]\n",
      " 12%|#2        | 65/536 [00:02<00:18, 25.28it/s]\n",
      " 13%|#2        | 68/536 [00:02<00:19, 23.94it/s]\n",
      " 13%|#3        | 71/536 [00:02<00:19, 23.53it/s]\n",
      " 14%|#4        | 77/536 [00:02<00:15, 29.46it/s]\n",
      " 15%|#5        | 81/536 [00:02<00:14, 30.92it/s]\n",
      " 16%|#6        | 87/536 [00:03<00:13, 32.77it/s]\n",
      " 17%|#7        | 93/536 [00:03<00:13, 32.49it/s]\n",
      " 18%|#8        | 98/536 [00:03<00:12, 35.07it/s]\n",
      " 19%|#9        | 102/536 [00:03<00:14, 29.22it/s]\n",
      " 20%|##        | 109/536 [00:03<00:11, 36.62it/s]\n",
      " 21%|##1       | 114/536 [00:03<00:12, 34.53it/s]\n",
      " 22%|##2       | 119/536 [00:03<00:11, 36.64it/s]\n",
      " 23%|##2       | 123/536 [00:04<00:12, 34.36it/s]\n",
      " 24%|##3       | 127/536 [00:04<00:15, 26.08it/s]\n",
      " 24%|##4       | 130/536 [00:04<00:19, 21.29it/s]\n",
      " 26%|##5       | 138/536 [00:04<00:14, 28.06it/s]\n",
      " 26%|##6       | 142/536 [00:04<00:13, 29.88it/s]\n",
      " 27%|##7       | 146/536 [00:04<00:14, 27.68it/s]\n",
      " 28%|##8       | 152/536 [00:05<00:12, 30.93it/s]\n",
      " 29%|##9       | 156/536 [00:05<00:13, 27.70it/s]\n",
      " 30%|##9       | 159/536 [00:05<00:14, 25.39it/s]\n",
      " 30%|###       | 162/536 [00:05<00:16, 22.37it/s]\n",
      " 31%|###1      | 167/536 [00:05<00:14, 25.74it/s]\n",
      " 32%|###2      | 173/536 [00:06<00:13, 27.65it/s]\n",
      " 34%|###3      | 181/536 [00:06<00:09, 36.24it/s]\n",
      " 35%|###4      | 185/536 [00:06<00:11, 31.43it/s]\n",
      " 35%|###5      | 189/536 [00:06<00:14, 23.49it/s]\n",
      " 36%|###5      | 192/536 [00:06<00:14, 24.26it/s]\n",
      " 36%|###6      | 195/536 [00:06<00:15, 22.16it/s]\n",
      " 37%|###6      | 198/536 [00:07<00:17, 19.26it/s]\n",
      " 39%|###8      | 207/536 [00:07<00:11, 28.50it/s]\n",
      " 39%|###9      | 211/536 [00:07<00:13, 24.78it/s]\n",
      " 40%|###9      | 214/536 [00:07<00:13, 24.11it/s]\n",
      " 41%|####1     | 222/536 [00:07<00:09, 31.77it/s]\n",
      " 42%|####2     | 226/536 [00:08<00:11, 27.09it/s]\n",
      " 43%|####2     | 229/536 [00:08<00:12, 24.99it/s]\n",
      " 44%|####3     | 234/536 [00:08<00:10, 27.57it/s]\n",
      " 44%|####4     | 237/536 [00:08<00:11, 25.38it/s]\n",
      " 45%|####4     | 240/536 [00:08<00:13, 21.73it/s]\n",
      " 45%|####5     | 243/536 [00:08<00:13, 22.14it/s]\n",
      " 46%|####5     | 246/536 [00:08<00:13, 21.91it/s]\n",
      " 47%|####7     | 253/536 [00:09<00:09, 30.60it/s]\n",
      " 48%|####7     | 257/536 [00:09<00:10, 26.52it/s]\n",
      " 49%|####8     | 260/536 [00:09<00:12, 22.41it/s]\n",
      " 49%|####9     | 263/536 [00:09<00:15, 17.99it/s]\n",
      " 50%|####9     | 266/536 [00:09<00:15, 17.06it/s]\n",
      " 50%|#####     | 268/536 [00:10<00:16, 16.41it/s]\n",
      " 50%|#####     | 270/536 [00:10<00:15, 16.66it/s]\n",
      " 51%|#####1    | 274/536 [00:10<00:12, 20.80it/s]\n",
      " 52%|#####1    | 277/536 [00:10<00:11, 22.22it/s]\n",
      " 52%|#####2    | 280/536 [00:10<00:13, 19.58it/s]\n",
      " 53%|#####3    | 286/536 [00:10<00:09, 25.98it/s]\n",
      " 54%|#####4    | 290/536 [00:10<00:09, 24.75it/s]\n",
      " 55%|#####4    | 293/536 [00:11<00:11, 21.75it/s]\n",
      " 56%|#####5    | 299/536 [00:11<00:09, 26.14it/s]\n",
      " 56%|#####6    | 302/536 [00:11<00:10, 22.34it/s]\n",
      " 57%|#####7    | 306/536 [00:11<00:09, 23.05it/s]\n",
      " 58%|#####8    | 312/536 [00:11<00:07, 29.82it/s]\n",
      " 60%|#####9    | 319/536 [00:11<00:05, 37.86it/s]\n",
      " 60%|######    | 324/536 [00:12<00:07, 28.67it/s]\n",
      " 61%|######1   | 329/536 [00:12<00:06, 32.14it/s]\n",
      " 62%|######2   | 333/536 [00:12<00:07, 27.94it/s]\n",
      " 63%|######3   | 338/536 [00:12<00:06, 28.54it/s]\n",
      " 64%|######3   | 342/536 [00:12<00:07, 24.41it/s]\n",
      " 64%|######4   | 345/536 [00:13<00:08, 21.40it/s]\n",
      " 66%|######5   | 352/536 [00:13<00:06, 29.05it/s]\n",
      " 66%|######6   | 356/536 [00:13<00:06, 27.33it/s]\n",
      " 67%|######7   | 360/536 [00:13<00:05, 29.68it/s]\n",
      " 68%|######8   | 365/536 [00:13<00:05, 31.98it/s]\n",
      " 69%|######8   | 369/536 [00:13<00:05, 31.66it/s]\n",
      " 70%|######9   | 373/536 [00:13<00:05, 30.43it/s]\n",
      " 70%|#######   | 377/536 [00:14<00:05, 28.88it/s]\n",
      " 71%|#######   | 380/536 [00:14<00:06, 25.39it/s]\n",
      " 72%|#######2  | 386/536 [00:14<00:04, 30.87it/s]\n",
      " 73%|#######2  | 390/536 [00:14<00:04, 32.15it/s]\n",
      " 74%|#######3  | 394/536 [00:14<00:05, 26.98it/s]\n",
      " 74%|#######4  | 397/536 [00:14<00:06, 22.04it/s]\n",
      " 75%|#######4  | 400/536 [00:15<00:06, 21.28it/s]\n",
      " 75%|#######5  | 403/536 [00:15<00:06, 21.77it/s]\n",
      " 76%|#######5  | 406/536 [00:15<00:05, 23.17it/s]\n",
      " 76%|#######6  | 409/536 [00:15<00:06, 20.78it/s]\n",
      " 77%|#######6  | 412/536 [00:15<00:05, 20.93it/s]\n",
      " 77%|#######7  | 415/536 [00:15<00:05, 20.80it/s]\n",
      " 78%|#######7  | 418/536 [00:15<00:06, 18.62it/s]\n",
      " 79%|#######8  | 422/536 [00:16<00:05, 21.77it/s]\n",
      " 79%|#######9  | 425/536 [00:16<00:05, 20.74it/s]\n",
      " 80%|########  | 429/536 [00:16<00:04, 24.27it/s]\n",
      " 81%|########  | 432/536 [00:16<00:04, 24.15it/s]\n",
      " 81%|########1 | 435/536 [00:16<00:04, 22.47it/s]\n",
      " 82%|########1 | 439/536 [00:16<00:04, 22.82it/s]\n",
      " 82%|########2 | 442/536 [00:16<00:04, 20.43it/s]\n",
      " 84%|########3 | 449/536 [00:17<00:03, 28.08it/s]\n",
      " 84%|########4 | 452/536 [00:17<00:03, 27.92it/s]\n",
      " 85%|########4 | 455/536 [00:17<00:03, 25.81it/s]\n",
      " 85%|########5 | 458/536 [00:17<00:02, 26.45it/s]\n",
      " 87%|########6 | 464/536 [00:17<00:02, 34.13it/s]\n",
      " 87%|########7 | 468/536 [00:17<00:01, 34.25it/s]\n",
      " 90%|########9 | 480/536 [00:17<00:01, 47.93it/s]\n",
      " 90%|######### | 485/536 [00:18<00:01, 34.87it/s]\n",
      " 91%|#########1| 489/536 [00:18<00:01, 30.44it/s]\n",
      " 92%|#########1| 493/536 [00:18<00:01, 28.61it/s]\n",
      " 93%|#########2| 497/536 [00:18<00:01, 30.38it/s]\n",
      " 93%|#########3| 501/536 [00:18<00:01, 28.22it/s]\n",
      " 95%|#########5| 510/536 [00:18<00:00, 36.48it/s]\n",
      " 96%|#########5| 514/536 [00:19<00:00, 29.73it/s]\n",
      " 97%|#########6| 518/536 [00:19<00:00, 25.36it/s]\n",
      " 98%|#########7| 525/536 [00:19<00:00, 32.53it/s]\n",
      " 99%|#########8| 529/536 [00:19<00:00, 27.31it/s]\n",
      "100%|#########9| 535/536 [00:19<00:00, 30.28it/s]\n",
      "100%|##########| 536/536 [00:19<00:00, 26.86it/s]\n",
      "\n",
      "  0%|          | 0/536 [00:00<?, ?it/s]\n",
      "  1%|          | 3/536 [00:00<00:19, 27.85it/s]\n",
      "  3%|2         | 14/536 [00:00<00:08, 63.74it/s]\n",
      "  4%|3         | 21/536 [00:00<00:16, 31.01it/s]\n",
      "  7%|6         | 35/536 [00:00<00:10, 49.72it/s]\n",
      "  8%|7         | 42/536 [00:00<00:10, 45.92it/s]\n",
      "  9%|8         | 48/536 [00:01<00:11, 44.30it/s]\n",
      " 11%|#         | 57/536 [00:01<00:08, 53.51it/s]\n",
      " 13%|#3        | 71/536 [00:01<00:06, 72.73it/s]\n",
      " 15%|#4        | 80/536 [00:01<00:09, 45.94it/s]\n",
      " 16%|#6        | 87/536 [00:01<00:10, 43.45it/s]\n",
      " 18%|#7        | 94/536 [00:01<00:09, 47.54it/s]\n",
      " 19%|#8        | 100/536 [00:02<00:08, 49.70it/s]\n",
      " 20%|#9        | 106/536 [00:02<00:08, 48.60it/s]\n",
      " 22%|##1       | 117/536 [00:02<00:07, 58.54it/s]\n",
      " 25%|##4       | 132/536 [00:02<00:06, 67.12it/s]\n",
      " 26%|##5       | 139/536 [00:02<00:09, 43.93it/s]\n",
      " 27%|##7       | 145/536 [00:03<00:08, 43.65it/s]\n",
      " 28%|##8       | 151/536 [00:03<00:09, 41.12it/s]\n",
      " 29%|##9       | 157/536 [00:03<00:09, 39.53it/s]\n",
      " 31%|###       | 165/536 [00:03<00:08, 44.42it/s]\n",
      " 32%|###1      | 170/536 [00:03<00:09, 39.06it/s]\n",
      " 33%|###2      | 175/536 [00:03<00:10, 35.63it/s]\n",
      " 33%|###3      | 179/536 [00:04<00:13, 27.41it/s]\n",
      " 36%|###5      | 192/536 [00:04<00:07, 43.62it/s]\n",
      " 37%|###7      | 199/536 [00:04<00:07, 42.39it/s]\n",
      " 38%|###8      | 204/536 [00:04<00:10, 31.80it/s]\n",
      " 40%|####      | 216/536 [00:04<00:07, 43.35it/s]\n",
      " 41%|####1     | 222/536 [00:04<00:06, 45.82it/s]\n",
      " 43%|####3     | 233/536 [00:05<00:05, 58.83it/s]\n",
      " 46%|####6     | 247/536 [00:05<00:04, 69.85it/s]\n",
      " 48%|####7     | 255/536 [00:05<00:04, 57.38it/s]\n",
      " 51%|#####     | 271/536 [00:05<00:03, 76.18it/s]\n",
      " 52%|#####2    | 280/536 [00:05<00:03, 69.31it/s]\n",
      " 54%|#####3    | 288/536 [00:05<00:04, 56.78it/s]\n",
      " 57%|#####6    | 303/536 [00:06<00:03, 74.94it/s]\n",
      " 58%|#####8    | 313/536 [00:06<00:04, 47.26it/s]\n",
      " 60%|#####9    | 321/536 [00:06<00:05, 37.58it/s]\n",
      " 61%|######1   | 327/536 [00:06<00:05, 36.49it/s]\n",
      " 62%|######2   | 335/536 [00:07<00:04, 42.34it/s]\n",
      " 65%|######4   | 346/536 [00:07<00:03, 47.70it/s]\n",
      " 66%|######5   | 352/536 [00:07<00:04, 39.83it/s]\n",
      " 67%|######6   | 358/536 [00:07<00:04, 38.31it/s]\n",
      " 68%|######8   | 366/536 [00:07<00:04, 40.34it/s]\n",
      " 70%|######9   | 373/536 [00:08<00:03, 41.67it/s]\n",
      " 72%|#######1  | 385/536 [00:08<00:03, 48.55it/s]\n",
      " 73%|#######2  | 391/536 [00:08<00:02, 50.51it/s]\n",
      " 75%|#######4  | 401/536 [00:08<00:02, 51.68it/s]\n",
      " 76%|#######6  | 409/536 [00:08<00:02, 48.73it/s]\n",
      " 79%|#######9  | 426/536 [00:08<00:01, 69.03it/s]\n",
      " 81%|########  | 434/536 [00:08<00:01, 68.72it/s]\n",
      " 82%|########2 | 442/536 [00:09<00:01, 69.39it/s]\n",
      " 84%|########3 | 450/536 [00:09<00:01, 63.86it/s]\n",
      " 86%|########5 | 460/536 [00:09<00:01, 68.95it/s]\n",
      " 88%|########7 | 470/536 [00:09<00:00, 66.25it/s]\n",
      " 89%|########8 | 477/536 [00:09<00:01, 52.26it/s]\n",
      " 90%|######### | 483/536 [00:09<00:01, 46.72it/s]\n",
      " 91%|#########1| 489/536 [00:09<00:00, 47.67it/s]\n",
      " 92%|#########2| 495/536 [00:10<00:00, 48.50it/s]\n",
      " 93%|#########3| 501/536 [00:10<00:00, 46.02it/s]\n",
      " 94%|#########4| 506/536 [00:10<00:00, 36.67it/s]\n",
      " 95%|#########5| 511/536 [00:10<00:00, 38.22it/s]\n",
      " 97%|#########7| 520/536 [00:10<00:00, 44.36it/s]\n",
      " 98%|#########7| 525/536 [00:10<00:00, 45.37it/s]\n",
      "100%|##########| 536/536 [00:10<00:00, 49.23it/s]\n",
      "C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project\\models.py:88: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(self.key_conv.weight, mode='fan_out')\n",
      "C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project\\models.py:89: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(self.value_conv.weight, mode='fan_out')\n",
      "C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project\\models.py:90: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(self.query_conv.weight, mode='fan_out')\n",
      "C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project\\models.py:91: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  init.normal(self.rel_t, 0, 1)\n",
      "C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\venv\\lib\\site-packages\\torch\\nn\\functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\venv\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "trained_model = \"Datasets/TrainedModel/\" + preTrainedModelType_dropdown.value + \"/\" + preTrainedModel_dropdown.value\n",
    "model_file = \"/Datasets/Video/DiningArea_EatingBreakfast/P02T11C01\"\n",
    "\n",
    "!python test.py \\\n",
    "-dataset TSU \\\n",
    "-mode rgb \\\n",
    "-split_setting CS \\\n",
    "-model PDAN \\\n",
    "-train False \\\n",
    "-num_channel 512 \\\n",
    "-lr 0.0002 \\\n",
    "-kernelsize 3 \\\n",
    "-APtype map \\\n",
    "-epoch 1 \\\n",
    "-batch_size 2 \\\n",
    "-comp_info TSU_CS_RGB_PDAN \\\n",
    "-load_model ./{trained_model}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-iCbepDNJTmJ"
   },
   "source": [
    "<h2> Evaluation Method</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-P6f7oWoJTmJ"
   },
   "source": [
    "After extracting the logits for the model, evaluation needs to be done to check if the model is trained. The team has created a feature to evaluate the model using the logits extracted from the previous section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMTsk5GXJTmJ"
   },
   "source": [
    "<h3> Evaluation step - Map by Frames </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "W8cHTYhlJTmK",
    "outputId": "27c9a583-a53b-4d52-eab9-d335c41ad4ef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"Frame_based_map.py\", line 49, in <module>\n",
      "    gt_new=make_gt(gt_file,logits,classes)\n",
      "  File \"Frame_based_map.py\", line 20, in make_gt\n",
      "    num_pred = logits[vid].shape[1]\n",
      "AttributeError: 'tuple' object has no attribute 'shape'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_to_run = os.getcwd() + \"\\TSU_evaluation\\Frame_map\"\n",
    "os.chdir(file_to_run)\n",
    "\n",
    "!python Frame_based_map.py -split CS -pkl_path PDAN_rgb_testing_results.pkl\n",
    "\n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rh0g-1tOJTmK"
   },
   "source": [
    "<h2> Evaluation Step - Map by Events </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UcNQO5YzJTmK",
    "outputId": "f865c0d8-df32-4142-eb42-9e7dc356f231"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thezh\\OneDrive\\Desktop\\Nvidia Project Local\\3104Project\n",
      "pred/test/\n",
      "================================================\n",
      "evaluation for method: test\n",
      "---- for theta = 0.300000\n",
      "-------- mAP_action =  0.07549673909968027\n",
      "-------- AP_action =  [0.25, 0.6618055555555554, 0, 0, 0, 0, 0, 0, 0.25, 0, 0, 0.5, 0, 0.0909090909090909, 0, 0.3333333333333333, 0.25, 0.6333333333333333, 0, 0.3333333333333333, 0, 0.047619047619047616, 0.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "-------- mAP_video =  0.34504021784934913\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "file_to_run = os.getcwd() + \"\\TSU_evaluation\\Event_map\"\n",
    "os.chdir(file_to_run)\n",
    "\n",
    "!python Event_based_map.py -pred_path pred -gt_path gt -theta 0.3\n",
    "\n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ny5d2SXwJTmK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0152c79d28494d0a97c8bbf75b1ddaa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Clear",
      "disabled": false,
      "icon": "check",
      "layout": "IPY_MODEL_a32db8cf334e4f88b6ae0eca5340264e",
      "style": "IPY_MODEL_59f55e3d4fcb42a99eb6f02a712e256b",
      "tooltip": ""
     }
    },
    "1a21d06fd50a427281e974526059adf3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2ca2a864de1645f29c57d980cd033da8",
       "IPY_MODEL_c2f314ef2d2041bf95367b904dd7eac2",
       "IPY_MODEL_1cd5d015de454b909ba2f5cd33e6294c",
       "IPY_MODEL_4d9e554ff49549cd87f551df25000601",
       "IPY_MODEL_abaf1854de82499585610d83b4d15fcc",
       "IPY_MODEL_0152c79d28494d0a97c8bbf75b1ddaa4"
      ],
      "layout": "IPY_MODEL_4cf0da92bc334d5b8613d463922e0bbc"
     }
    },
    "1cd5d015de454b909ba2f5cd33e6294c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "PDAN_TSU_RGB"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "Pretrain Models:",
      "description_tooltip": null,
      "disabled": false,
      "index": 0,
      "layout": "IPY_MODEL_2787953476634e2a9a0b79fcf1ff81b3",
      "style": "IPY_MODEL_bd2cfc3055734bc1b78d780f63350a57"
     }
    },
    "24023bc1cb9e48029857c7af3190ef7f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2787953476634e2a9a0b79fcf1ff81b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ca2a864de1645f29c57d980cd033da8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "1",
       "2",
       "4",
       "8",
       "16",
       "32",
       "64"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "batch_size:",
      "description_tooltip": null,
      "disabled": false,
      "index": 0,
      "layout": "IPY_MODEL_2d25422d40a048058177c4b9e25f51da",
      "style": "IPY_MODEL_91c8988cbcc14bd08192f952b2a35e2d"
     }
    },
    "2d25422d40a048058177c4b9e25f51da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41b7d8e942f3441ca42b9e9639d75ce2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4cf0da92bc334d5b8613d463922e0bbc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d9e554ff49549cd87f551df25000601": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "smarthome_CV_51.json",
       "smarthome_CS_51.json"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "Data:",
      "description_tooltip": null,
      "disabled": false,
      "index": 0,
      "layout": "IPY_MODEL_41b7d8e942f3441ca42b9e9639d75ce2",
      "style": "IPY_MODEL_f7198ea373944e6492143832e3c34cef"
     }
    },
    "59f55e3d4fcb42a99eb6f02a712e256b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "7a306fa8f6d6474898754f5ea217831b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "826d45875a0342a9a4699408cc3c871d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d02f73b32f04506a3dc24ddc802bbf8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "91c8988cbcc14bd08192f952b2a35e2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a32db8cf334e4f88b6ae0eca5340264e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "abaf1854de82499585610d83b4d15fcc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Add",
      "disabled": false,
      "icon": "check",
      "layout": "IPY_MODEL_24023bc1cb9e48029857c7af3190ef7f",
      "style": "IPY_MODEL_8d02f73b32f04506a3dc24ddc802bbf8",
      "tooltip": ""
     }
    },
    "bd2cfc3055734bc1b78d780f63350a57": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c2f314ef2d2041bf95367b904dd7eac2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "IntSliderView",
      "continuous_update": true,
      "description": "Epoch:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_826d45875a0342a9a4699408cc3c871d",
      "max": 190,
      "min": 2,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": "d",
      "step": 2,
      "style": "IPY_MODEL_7a306fa8f6d6474898754f5ea217831b",
      "value": 2
     }
    },
    "f7198ea373944e6492143832e3c34cef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
